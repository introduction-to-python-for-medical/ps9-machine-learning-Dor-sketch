{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/yotam-biu/ps9/blob/main/parkinsons.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "UoYQV1UbSAuF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "/content/parkinsons.csv: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Download the data from your GitHub repository\n",
    "!wget https://raw.githubusercontent.com/yotam-biu/ps9/main/parkinsons.csv -O /content/parkinsons.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hWY_BLnnWuEH"
   },
   "source": [
    "\n",
    "\n",
    "## 1. **Load the dataset:**  \n",
    "\n",
    "   After running the first cell of this notebook, the file `parkinson.csv` will appear in the `Files` folder.\n",
    "   You need to loaded the file as a DataFrame.  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g1KB69V5Wtg5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_csv('parkinsons.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TEHB7g0tdk1Y"
   },
   "source": [
    "## 2. **Select features:**  \n",
    "\n",
    "   - Choose **two features** as inputs for the model.  \n",
    "   - Identify **one feature** to use as the output for the model.  \n",
    "\n",
    "  #### Advice:  \n",
    "  - You can refer to the paper available in the GitHub repository for insights into the dataset and guidance on identifying key features for the input and output.  \n",
    "  - Alternatively, consider creating pair plots or using other EDA methods we learned in the last lecture to explore the relationships between features and determine which ones are most relevant.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "UA7GX4gMdxGf"
   },
   "outputs": [],
   "source": [
    "# Selecting relevant features based on the paper\n",
    "# Using the provided column names\n",
    "features = ['HNR', 'RPDE']\n",
    "output = 'PPE'\n",
    "\n",
    "X = data[features]\n",
    "y = data[output]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S0WSZq99WyvB"
   },
   "source": [
    "## 3. **Scale the data:**\n",
    "\n",
    "   Apply the `MinMaxScaler` to scale the two input columns to a range between 0 and 1.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "HGdRn2P6WeuC"
   },
   "outputs": [],
   "source": [
    "# Scaling the features to [-1, 1] as suggested in the paper\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "y_scaled = scaler.fit_transform(y.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O3VowsT1XVkY"
   },
   "source": [
    "## 4. **Split the data:**\n",
    "\n",
    "   Divide the dataset into a training set and a validation set.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "2ycT-D2FYVWf"
   },
   "outputs": [],
   "source": [
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HYaq4tmqYV6C"
   },
   "source": [
    "## 5. **Choose a model:**  \n",
    "\n",
    "   Select a model to train on the data.  \n",
    "\n",
    "   #### Advice:  \n",
    "   - Consider using the model discussed in the paper from the GitHub repository as a reference.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "3046tEKrhPlz"
   },
   "outputs": [],
   "source": [
    "# Building the SVM regression model with a radial basis function (RBF) kernel\n",
    "svm_model = SVR(kernel='rbf', C=1.0, gamma='scale')\n",
    "\n",
    "# Training the model\n",
    "svm_model.fit(X_train, y_train.ravel())\n",
    "\n",
    "# Making predictions\n",
    "y_pred = svm_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wz0m7c_MYpei"
   },
   "source": [
    "# 6. **Test the accuracy:**  \n",
    "\n",
    "   Evaluate the model's accuracy on the test set. Ensure that the accuracy is at least **0.8**.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "1fN3T8xGYu1U"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.0751\n",
      "R-squared: 0.4569\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "print(f\"R-squared: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MSsFRlk2cNyH"
   },
   "source": [
    "## 7. **Save and upload the model:**  \n",
    "\n",
    "   After you are happy with your results, save the model with the `.joblib` extension and upload it to your GitHub repository main folder.\n",
    "   \n",
    "   Additionally, update the `config.yaml` file with the list of selected features and the model's joblib file name.  \n",
    "\n",
    "\n",
    "example:  \n",
    "```yaml\n",
    "selected_features: [\"A\", \"B\"]  \n",
    "path: \"my_model.joblib\"  \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "7X4gb6vGgyoZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as svm_model.joblib\n",
      "Configuration file 'config.yaml' created.\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import joblib\n",
    "\n",
    "# Save the trained model to a file\n",
    "model_filename = 'svm_model.joblib'\n",
    "joblib.dump(svm_model, model_filename)\n",
    "print(f\"Model saved as {model_filename}\")\n",
    "\n",
    "# Create and save the config.yaml file\n",
    "config = {\n",
    "    'selected_features': features,\n",
    "    'path': model_filename\n",
    "}\n",
    "\n",
    "with open('config.yaml', 'w') as config_file:\n",
    "    yaml.dump(config, config_file)\n",
    "print(\"Configuration file 'config.yaml' created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GiUXpS7FgAmd"
   },
   "source": [
    "## 8. **Copy the code:**  \n",
    "\n",
    "   Copy and paste all the code from this notebook into a `main.py` file in the GitHub repository.  \n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNtbwirCNlFqEzI3gLjQKri",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
